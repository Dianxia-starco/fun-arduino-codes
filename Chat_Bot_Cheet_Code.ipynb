{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dianxia-starco/fun-arduino-codes/blob/main/Chat_Bot_Cheet_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPyLmKojGGwP"
      },
      "outputs": [],
      "source": [
        "# Install all required libraries for the chatbot\n",
        "# LangChain: Framework for building LLM applications\n",
        "# Google Generative AI: Python SDK for Gemini API\n",
        "# Gradio: Creates web interface for the chatbot\n",
        "# HuggingFace Hub: Optional for model deployment\n",
        "!pip install -U langchain langchain-community langchain-google-genai\n",
        "!pip install -U google-generativeai\n",
        "!pip install -U gradio\n",
        "!pip install -U huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P4b7nKGD8RH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzPZ54A8Q4El"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VclINVmUGsb1"
      },
      "source": [
        "**How to get Google Gemini API Key?**\n",
        "\n",
        "- Go to https://aistudio.google.com/app/api-keys\n",
        "- Click \"Create API Key\"\n",
        "- Copy the API Key for your use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fci9byLAGrW6"
      },
      "outputs": [],
      "source": [
        "GEMINI_API_KEY=\"...\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhO7eYfNRGU6"
      },
      "source": [
        "\n",
        "- Similar to Gemini Model we can also use HuggingFace Transformer Models.\n",
        "- Reference links: https://python.langchain.com/docs/integrations/providers/huggingface , https://python.langchain.com/docs/integrations/llms/huggingface_hub.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvYWPZnSQr02"
      },
      "outputs": [],
      "source": [
        "# from langchain.llms import HuggingFacePipeline\n",
        "# hf = HuggingFacePipeline.from_model_id(\n",
        "#     model_id=\"gpt2\",\n",
        "#     task=\"text-generation\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEV6hMJG4xt"
      },
      "outputs": [],
      "source": [
        "# Initialize Gemini model\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Custom LLM wrapper for Gemini\n",
        "class GeminiLLM:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.memory_history = []\n",
        "\n",
        "    def predict(self, user_message):\n",
        "        # Build conversation context\n",
        "        full_prompt = \"You are a helpful assistant to answer user queries.\\n\"\n",
        "        for msg in self.memory_history:\n",
        "            full_prompt += f\"{msg}\\n\"\n",
        "        full_prompt += f\"User: {user_message}\\nChatbot:\"\n",
        "\n",
        "        # Generate response\n",
        "        response = self.model.generate_content(full_prompt)\n",
        "        answer = response.text\n",
        "\n",
        "        # Update memory\n",
        "        self.memory_history.append(f\"User: {user_message}\")\n",
        "        self.memory_history.append(f\"Chatbot: {answer}\")\n",
        "\n",
        "        # Keep only last 10 exchanges\n",
        "        if len(self.memory_history) > 20:\n",
        "            self.memory_history = self.memory_history[-20:]\n",
        "\n",
        "        return answer\n",
        "\n",
        "llm_chain = GeminiLLM(gemini_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl77cfyIG85T"
      },
      "outputs": [],
      "source": [
        "def get_text_response(user_message,history):\n",
        "    response = llm_chain.predict(user_message = user_message)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JxyOMt_HAr-"
      },
      "outputs": [],
      "source": [
        "demo = gr.ChatInterface(get_text_response, examples=[\"How are you doing?\",\"What are your interests?\",\"Which places do you like to visit?\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWVT_2_KHE2G"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True) #To create a public link, set `share=True` in `launch()`. To enable errors and logs, set `debug=True` in `launch()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLLzAlLeIlcF"
      },
      "source": [
        "##**Publishing your code to Hugging Face**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmFkrSfFI2hv"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ijRWEjlI8NI"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPcVNQxpJBT7"
      },
      "outputs": [],
      "source": [
        "HUGGING_FACE_REPO_ID = \"<Hugging Face User Name/Repo Name>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc4apOwzTzYS"
      },
      "source": [
        "**Adding Secret Variables in Hugging Face Account:**\n",
        "\n",
        "- Open your Space\n",
        "- Click on Settings Button\n",
        "- Checkout to **Variables and secrets** section\n",
        "- Create New Secrets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAj6X5xwJWGh"
      },
      "source": [
        "*Note*: Make sure to add your **google-generativeai_API_KEY** in Secret key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/ChatBotWithGemini\n",
        "!wget -P  /content/ChatBotWithGemini/ https://s3.ap-south-1.amazonaws.com/cdn1.ccbp.in/GenAI-Workshop/ChatBotWIthGeminiLangchain/app.py\n",
        "!wget -P /content/ChatBotWithGemini/ https://s3.ap-south-1.amazonaws.com/cdn1.ccbp.in/GenAI-Workshop/ChatBotWIthGeminiLangchain/requirements.txt"
      ],
      "metadata": {
        "id": "9kQS8odI-xTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF-XF-_gJF8g"
      },
      "outputs": [],
      "source": [
        "%cd /content/ChatBotWithGemini\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"./requirements.txt\",\n",
        "    path_in_repo=\"requirements.txt\",\n",
        "    repo_id=HUGGING_FACE_REPO_ID,\n",
        "    repo_type=\"space\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"./app.py\",\n",
        "    path_in_repo=\"app.py\",\n",
        "    repo_id=HUGGING_FACE_REPO_ID,\n",
        "    repo_type=\"space\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO2KJ3r4KdW4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}